{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Read and process the video\n",
    "video_path = 'C:/Users/HP/Desktop/image assign/Project Video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Step 2: Preprocessing & noise removal\n",
    "def preprocess_frame(frame):\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply GaussianBlur for noise removal\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    return blurred\n",
    "\n",
    "\n",
    "# Step 3: Segmentation\n",
    "def segment_frame(frame):\n",
    "    # Apply adaptive thresholding to detect subtitles\n",
    "    _, thresh = cv2.threshold(frame, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Extract words from contours\n",
    "    words = []\n",
    "    for contour in contours:\n",
    "        # Calculate contour area\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # Filter out shapes based on contour area\n",
    "        if area > 100:\n",
    "            # Get the minimum bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Filter out shapes based on aspect ratio\n",
    "            aspect_ratio = w / h\n",
    "            if 0.2 < aspect_ratio < 5:\n",
    "                words.append(((x, y), (x + w, y + h)))\n",
    "    \n",
    "    return thresh, words\n",
    "\n",
    "# Step 4: Calculate bounding boxes dimensions\n",
    "def calculate_bounding_boxes(words):\n",
    "    # Sort words by y-coordinate to handle multiline subtitles\n",
    "    sorted_words = sorted(words, key=lambda x: x[0][1])\n",
    "\n",
    "    # Group words into lines based on y-coordinate proximity\n",
    "    lines = []\n",
    "    current_line = [sorted_words[0]]\n",
    "    for word in sorted_words[1:]:\n",
    "        if abs(word[0][1] - current_line[-1][1][1]) < 20:  # Adjust this threshold as needed\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = [word]\n",
    "    lines.append(current_line)\n",
    "\n",
    "    # Calculate bounding boxes for lines and words\n",
    "    subtitle_boxes = [cv2.boundingRect(np.array([point for box in line for point in box])) for line in lines]\n",
    "    word_boxes = [cv2.boundingRect(np.array(word)) for line in lines for word in line]\n",
    "\n",
    "    return subtitle_boxes, word_boxes\n",
    "\n",
    "# Step 5: Draw bounding boxes on the video frames\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading video or end of video reached.\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    preprocessed_frame = preprocess_frame(frame)\n",
    "\n",
    "    # Segment the frame to detect subtitles and words\n",
    "    thresh, words = segment_frame(preprocessed_frame)\n",
    "\n",
    "    # Calculate bounding box dimensions\n",
    "    subtitle_boxes, word_boxes = calculate_bounding_boxes(words)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for box in subtitle_boxes:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red for subtitles\n",
    "\n",
    "    for box in word_boxes:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green for words\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Video with Bounding Boxes', frame)\n",
    "\n",
    "    # Break the loop when 'q' key is pressed\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
